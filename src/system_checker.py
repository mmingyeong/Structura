#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# @Author: Mingyeong Yang
# @Date: 2025-03-04
# @Filename: system_checker.py

import os
import platform
import psutil
import numpy as np
import cupy as cp
import yaml
from datetime import date  # âœ… ì˜¤ëŠ˜ ë‚ ì§œ ì¶”ê°€
from logger import logger

# âœ… PyTorch ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
try:
    import torch
    torch_version = torch.__version__
except ModuleNotFoundError:
    torch_version = "Not Installed"

# âœ… ìµœì‹  ì—…ë°ì´íŠ¸ ë‚ ì§œ (ì˜¤ëŠ˜ ë‚ ì§œ ìë™ ì„¤ì •)
LAST_UPDATE_DATE = date.today().strftime("%Y-%m-%d")

# âœ… ì¼ë°˜ì ì¸ GPU ì„±ëŠ¥ ê¸°ì¤€ (ì—…ê·¸ë ˆì´ë“œ ì¶”ì²œ ê¸°ì¤€)
RECOMMENDED_GPUS = {
    "Deep Learning": ["NVIDIA H100", "NVIDIA A100", "RTX 4090", "RTX 3090", "Tesla V100"],
    "High Performance Computing": ["NVIDIA H100", "A100", "Tesla P100"],
    "General Computing": ["RTX 4060", "RTX 3060", "GTX 1660 Super"],
}

class SystemChecker:
    """ì‹œìŠ¤í…œ í™˜ê²½ì„ ì²´í¬í•˜ì—¬ GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ë° ì„±ëŠ¥ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤."""

    def __init__(self, verbose=False):
        """âœ… ì´ˆê¸°í™” ì‹œ GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ë¨¼ì € í™•ì¸"""
        self.use_gpu = self.check_gpu_availability()
        self.verbose = verbose  # âœ… ìƒì„¸ ë¶„ì„ í™œì„±í™” ì—¬ë¶€
        self.gpu_info = []
        self.recommended_gpus = set()  # âœ… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ set ì‚¬ìš©
        self.cpu_cores = None
        self.total_memory = None
        self.python_version = None
        self.numpy_version = None
        self.cupy_version = None
        self.torch_version = torch_version

    def check_gpu_availability(self):
        """âœ… GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ í™˜ê²½ì¸ì§€ í™•ì¸í•˜ê³  True/False ë°˜í™˜"""
        try:
            if cp.cuda.runtime.getDeviceCount() > 0:
                return True
        except (cp.cuda.runtime.CUDARuntimeError, RuntimeError):
            pass
        return False

    def check_gpu(self):
        """ğŸ–¥ GPU ì„±ëŠ¥ ë¶„ì„ ë° ì¶”ì²œ"""
        try:
            num_gpus = cp.cuda.runtime.getDeviceCount()
            if num_gpus > 0:
                for i in range(num_gpus):
                    device = cp.cuda.Device(i)
                    props = cp.cuda.runtime.getDeviceProperties(i)
                    name = props["name"].decode("utf-8")  # âœ… ë°”ì´íŠ¸ ë¬¸ìì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    total_mem = props["totalGlobalMem"] / (1024 ** 3)  # GB ë³€í™˜
                    cuda_cores = props["multiProcessorCount"]  # CUDA ì½”ì–´ ìˆ˜
                    clock_speed = props["clockRate"] / 1e6  # GHz ë³€í™˜

                    gpu_details = (
                        f"ğŸ–¥ GPU {i}: {name} ({total_mem:.2f} GB, "
                        f"{cuda_cores} CUDA cores, {clock_speed:.2f} GHz)"
                    )
                    self.gpu_info.append(gpu_details)

                    # âœ… ì‚¬ìš© ëª©ì ì— ë”°ë¥¸ GPU ì¶”ì²œ (ì´ë¯¸ ì¶©ë¶„íˆ ì¢‹ì€ GPUëŠ” ì¶”ì²œ ì•ˆ í•¨)
                    recommended_gpu = self.recommend_gpu(name, total_mem, cuda_cores)
                    if recommended_gpu and recommended_gpu != name:
                        self.recommended_gpus.add(recommended_gpu)  # âœ… ì¤‘ë³µ ë°©ì§€

        except (cp.cuda.runtime.CUDARuntimeError, RuntimeError):
            self.gpu_info.append("âš ï¸ No GPU detected. Using CPU (NumPy fallback mode).")
            self.use_gpu = False

    def recommend_gpu(self, current_gpu, memory_gb, cuda_cores):
        """ğŸ›  í˜„ì¬ ì‚¬ìš©ìì˜ GPU ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ì¶”ì²œ GPU ë°˜í™˜"""
        # âœ… A100 40GB ë˜ëŠ” 80GB ì‚¬ìš© ì¤‘ì´ë©´ ì—…ê·¸ë ˆì´ë“œ ì¶”ì²œí•˜ì§€ ì•ŠìŒ
        if any(a100_variant in current_gpu for a100_variant in ["A100", "A100-PCIE", "A100 80GB"]):
            return None
        
        # âœ… H100 ì‚¬ìš© ì¤‘ì´ë©´ ì—…ê·¸ë ˆì´ë“œ ì¶”ì²œí•˜ì§€ ì•ŠìŒ
        if "H100" in current_gpu:
            return None

        # âœ… ë©”ëª¨ë¦¬ê°€ 8GB ë¯¸ë§Œì´ê±°ë‚˜ CUDA ì½”ì–´ê°€ ì ìœ¼ë©´ A100 ì´ìƒ ì¶”ì²œ
        if memory_gb < 8 or cuda_cores < 2500:
            return RECOMMENDED_GPUS["Deep Learning"][0]  # NVIDIA H100 ì¶”ì²œ
        elif "GTX" in current_gpu or "RTX 2060" in current_gpu:
            return RECOMMENDED_GPUS["General Computing"][0]  # RTX 4060 ì¶”ì²œ
        elif "Tesla" in current_gpu and memory_gb < 32:
            return RECOMMENDED_GPUS["High Performance Computing"][0]  # H100 ì¶”ì²œ
        return None

    def check_cpu(self):
        """ğŸ–¥ CPU ë° RAM ì •ë³´ í™•ì¸"""
        self.cpu_cores = psutil.cpu_count(logical=True)
        self.total_memory = psutil.virtual_memory().total / (1024 ** 3)

    def check_python_libraries(self):
        """ğŸ Python ë° ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ í™•ì¸"""
        self.python_version = platform.python_version()
        self.numpy_version = np.__version__
        self.cupy_version = cp.__version__ if cp else "Not Installed"

    def log_environment_analysis(self):
        """ğŸ›  ê°œë°œ í™˜ê²½ ë¶„ì„ ë° í‰ê°€ (Verbose ëª¨ë“œ í™œì„±í™” ì‹œ)"""
        if not self.verbose:
            return
        
        logger.info(f"ğŸ“… Environment analysis based on SystemChecker update: {LAST_UPDATE_DATE}")
        
        if self.python_version < "3.9":
            logger.warning(f"âš ï¸ Python {self.python_version} is outdated. Upgrade to Python 3.9+ recommended.")
        
        if self.torch_version == "Not Installed":
            logger.warning("âš ï¸ PyTorch is not installed. Consider installing it for deep learning.")
        
        logger.info(f"ğŸ Python Version: {self.python_version}")
        logger.info(f"ğŸ“¦ NumPy Version: {self.numpy_version}")
        logger.info(f"ğŸ“¦ CuPy Version: {self.cupy_version}")
        logger.info(f"ğŸ“¦ PyTorch Version: {self.torch_version}")

    def run_all_checks(self):
        """âœ… ëª¨ë“  ì‹œìŠ¤í…œ ì²´í¬ ì‹¤í–‰"""
        self.check_cpu()
        self.check_gpu()
        self.check_python_libraries()
        self.log_environment_analysis()  # âœ… í™˜ê²½ ë¶„ì„ ì¶”ê°€

    def log_results(self):
        """ğŸ” ì‹œìŠ¤í…œ ì²´í¬ ê²°ê³¼ ë¡œê¹…"""
        logger.info("ğŸ” Running System Check...")

        # âœ… GPU ì •ë³´ ì¶œë ¥
        if self.gpu_info:
            for gpu in self.gpu_info:
                logger.info(gpu)

        # âœ… GPU ì—…ê·¸ë ˆì´ë“œ ì¶”ì²œ
        if self.recommended_gpus:
            for rec_gpu in self.recommended_gpus:
                logger.warning(f"âš ï¸ Recommended Upgrade: {rec_gpu}")

        logger.info(f"ğŸ–¥ CPU Cores: {self.cpu_cores}")
        logger.info(f"ğŸ’¾ Total RAM: {self.total_memory:.2f} GB")
        logger.info(f"ğŸš€ Using GPU: {self.use_gpu}")
        logger.info("âœ… System check complete.")

    def get_use_gpu(self):
        """âœ… í˜„ì¬ ì„¤ì •ëœ use_gpu ê°’ì„ ë°˜í™˜"""
        return self.use_gpu
