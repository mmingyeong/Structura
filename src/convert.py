#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# @Author: Mingyeong Yang (mmingyeong@kasi.re.kr)
# @Date: 2025-03-03
# @Filename: convert.py
# structura/convert.py

import h5py
import numpy as np
import cupy as cp
import os
import psutil
import struct
from tqdm import tqdm
from logger import logger  # ê³µí†µ ë¡œê±° ê°€ì ¸ì˜¤ê¸°
from multiprocessing import Pool, cpu_count

class SimulationDataConverter:
    """Converts various cosmological simulation formats (HDF5, GADGET, ASCII) to .npy or .npz."""

    def __init__(self, input_path, output_folder, chunk_size=None, num_processes=None, size_threshold=500 * 1e6, use_gpu=True):
        """
        Parameters
        ----------
        input_path : str
            Path to the input data file or folder.
        output_folder : str
            Folder where the converted .npy or .npz files will be stored.
        chunk_size : int, optional
            Number of rows per chunk. If None, it is determined automatically.
        num_processes : int, optional
            Number of parallel processes (default: CPU count).
        size_threshold : int, optional
            File size threshold (in bytes) under which conversion is skipped.
        use_gpu : bool, optional
            If True, CuPy will be used for GPU acceleration (default: True).
        """
        self.input_path = input_path
        self.output_folder = output_folder
        self.use_gpu = use_gpu
        self.num_processes = num_processes or cpu_count()
        self.size_threshold = size_threshold  # ë³€í™˜ ìƒëµ ê¸°ì¤€ (ê¸°ë³¸ê°’: 500MB)
        os.makedirs(self.output_folder, exist_ok=True)

        # ë°ì´í„° í˜•ì‹ ìë™ ê°ì§€
        self.data_format = self.detect_format()
        if not self.data_format:
            raise ValueError("âŒ Unsupported data format!")

        # ìµœì ì˜ chunk_size ìë™ ì„¤ì •
        self.chunk_size = chunk_size or self.get_optimal_chunk_size()
        logger.info(f"ğŸ”§ ìë™ ì„¤ì •ëœ chunk_size: {self.chunk_size:,}")

        # íŒŒì¼ í¬ê¸° í™•ì¸ (ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€)
        try:
            file_size = os.path.getsize(self.input_path)
            logger.info(f"ğŸ“‚ íŒŒì¼ í¬ê¸°: {file_size / 1e6:.2f} MB")
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ í¬ê¸° í™•ì¸ ì‹¤íŒ¨: {e}")
            file_size = float("inf")  # ì˜ˆì™¸ ë°œìƒ ì‹œ ë³€í™˜ ìˆ˜í–‰

        # ë³€í™˜ ì—¬ë¶€ ê²°ì •
        self.needs_conversion = file_size >= self.size_threshold
        if not self.needs_conversion:
            logger.info("âœ… íŒŒì¼ í¬ê¸°ê°€ ì‘ì•„ì„œ ë³€í™˜ ì—†ì´ ì›ë³¸ ì‚¬ìš©")

    def get_optimal_chunk_size(self):
        """RAM ìš©ëŸ‰ê³¼ I/O ì†ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ìë™ìœ¼ë¡œ chunk_size ì„¤ì •"""
        total_ram = psutil.virtual_memory().total  # ì „ì²´ RAM ìš©ëŸ‰ (bytes)
        if total_ram < 16 * 1e9:  # RAM 16GB ë¯¸ë§Œ
            return 1_000_000  # 1M ê°œ
        elif total_ram < 64 * 1e9:  # RAM 16GB ~ 64GB
            return 10_000_000  # 10M ê°œ
        else:  # RAM 64GB ì´ìƒ
            return 50_000_000  # 50M ê°œ

    def detect_format(self):
        """Detects the input file format."""
        if self.input_path.endswith((".hdf5", ".h5")):
            return "HDF5"
        elif self.input_path.endswith((".bin", ".dat")):
            return "GADGET"
        elif self.input_path.endswith((".csv", ".txt")):
            return "ASCII"
        elif self.input_path.endswith((".npy", ".npz")):
            return "NUMPY"
        return None

    def convert(self, npyornpz="npy"):
        """Converts the detected format into .npy or .npz."""

        if not self.needs_conversion:
            logger.info("âœ… ë³€í™˜ ì—†ì´ ì›ë³¸ ì‚¬ìš©.")
            return
        
        # ë³€í™˜ ìˆ˜í–‰
        logger.info(f"ğŸ”„ Converting {self.input_path} ({self.data_format}) to {npyornpz.upper()}...")

        if self.data_format == "HDF5":
            self.convert_hdf5(npyornpz)
        elif self.data_format == "GADGET":
            self.convert_gadget(npyornpz)
        elif self.data_format == "ASCII":
            self.convert_ascii(npyornpz)
        elif self.data_format == "NUMPY":
            logger.info("âœ… No conversion needed. Already in NumPy format.")
        else:
            raise ValueError("âŒ Unsupported data format!")

    def _find_hdf5_datasets(self):
        """HDF5 ë‚´ë¶€ì˜ ë°ì´í„°ì…‹ ëª©ë¡ì„ ë°˜í™˜ (ì§„í–‰ë¥  í‘œì‹œ í¬í•¨)"""
        datasets = []
        with h5py.File(self.input_path, "r") as hdf5_file:
            groups = list(hdf5_file.keys())
            for group in tqdm(groups, desc="ğŸ” Searching HDF5 datasets"):
                if isinstance(hdf5_file[group], h5py.Group):
                    for dataset in hdf5_file[group].keys():
                        full_path = f"{group}/{dataset}"
                        datasets.append(full_path)
                        logger.info(f"ğŸ“Œ Found dataset: {full_path}")

        return datasets

    def convert_hdf5(self, npyornpz, dataset_name=None):
        """Converts HDF5 data to .npy or .npz with user dataset selection."""
        
        if dataset_name is None:
            available_datasets = self._find_hdf5_datasets()
            
            if not available_datasets:
                raise ValueError("âŒ HDF5 íŒŒì¼ì—ì„œ ìœ íš¨í•œ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ!")

            # ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•˜ë„ë¡ ì˜µì…˜ ì œê³µ
            logger.info("ğŸ’¡ Available datasets:")
            for idx, ds in enumerate(available_datasets):
                logger.info(f"  [{idx}] {ds}")

            # CLI í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ê²½ìš°
            try:
                selected_idx = int(input("ğŸ‘‰ ë³€í™˜í•  ë°ì´í„°ì…‹ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
                dataset_name = available_datasets[selected_idx]
            except (ValueError, IndexError):
                raise ValueError("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

        logger.info(f"âœ… ì„ íƒëœ ë°ì´í„°ì…‹: {dataset_name}")

        with h5py.File(self.input_path, "r") as hdf5_file:
            dataset_size = hdf5_file[dataset_name].shape[0]  # ì´ ë°ì´í„° ê°œìˆ˜ í™•ì¸

        # ğŸ”¥ datasetì„ `multiprocessing.Pool`ì— ì „ë‹¬í•˜ì§€ ì•Šê³ , ì¸ë±ìŠ¤ ì •ë³´ë§Œ ì „ë‹¬
        chunk_indices = list(
            tqdm(
                [(self.input_path, dataset_name, i, min(i + self.chunk_size, dataset_size), idx, npyornpz)
                for idx, i in enumerate(range(0, dataset_size, self.chunk_size))],
                desc="ğŸ›  Preparing chunk indices"
            )
        )

        with Pool(self.num_processes) as pool:
            list(tqdm(pool.starmap(self._process_hdf5_chunk, chunk_indices), total=len(chunk_indices), desc="ğŸš€ Converting HDF5 chunks"))

    def _process_hdf5_chunk(self, hdf5_path, dataset_name, start_idx, end_idx, chunk_id, npyornpz):
        """Processes a chunk of an HDF5 file with tqdm progress tracking."""
        with h5py.File(hdf5_path, "r") as f:  # ğŸ”¥ ì—¬ê¸°ì„œ ë‹¤ì‹œ HDF5 íŒŒì¼ì„ ì—´ì–´ì•¼ í•¨!
            dataset = f[dataset_name]
            chunk = dataset[start_idx:end_idx]

        if self.use_gpu:
            chunk = cp.asarray(chunk)  # âœ… NumPy â†’ CuPy ë³€í™˜
            logger.info(f"ğŸš€ GPU enabled for chunk {chunk_id}")

        chunk_file = os.path.join(self.output_folder, f"chunk_{chunk_id}.{npyornpz}")
        if npyornpz == "npy":
            np.save(chunk_file, chunk)
        else:
            np.savez_compressed(chunk_file, data=chunk)

        logger.info(f"âœ… Saved chunk {chunk_id}: {chunk_file}")

    def convert_gadget(self, npyornpz):
        """Converts GADGET binary data to .npy or .npz with tqdm tracking."""
        with open(self.input_path, "rb") as f:
            header_size = struct.unpack("I", f.read(4))[0]  # í—¤ë” í¬ê¸° ë™ì  ê°ì§€
            f.seek(header_size)
            data = np.fromfile(f, dtype=np.float32).reshape(-1, 3)

        if npyornpz == "npy":
            np.save(os.path.join(self.output_folder, data))
        else:
            np.savez_compressed(os.path.join(self.output_folder, data=data))
        logger.info(f"âœ… Converted GADGET to {npyornpz.upper()}.")


    def convert_ascii(self, npyornpz):
        """Converts ASCII (CSV or TXT) to .npy or .npz with tqdm tracking."""
        data = np.loadtxt(self.input_path, delimiter=None)  # ìë™ êµ¬ë¶„ì ê°ì§€
        output_file = os.path.join(self.output_folder, f"converted.{npyornpz}")

        if npyornpz == "npy":
            np.save(output_file, data)
        else:
            np.savez_compressed(output_file, data=data)
        logger.info(f"âœ… Converted ASCII to {npyornpz.upper()}.")